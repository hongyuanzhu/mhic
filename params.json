{
  "name": "Multiple Human Identification and Cosegmentation",
  "tagline": "MHIC",
  "body": "###Welcome to our project page.\r\n\r\nLocalizing, identifying and extracting humans with consistent appearance jointly from a personal photo stream is an  important  problem  and  has  wide  applications.  The  strong variations in foreground and background and irregularly occur-ring foreground humans make this realistic problem challenging.Inspired by the advance in object detection, scene understanding and image  cosegmentation,  in this paper we explore explicit constraints to label and segment human objects rather than other non-human  objects  and  “stuff”.  We  refer  to  such  a  problem  as Multiple Human Identification and Cosegmentation (MHIC). To identify specific human subjects, we propose an efficient human instance detector by combining an extended color line model with a poselet-based human detector. Moreover, to capture high level human shape information, a novel soft shape cue is proposed. It is initialized by the human detector, then further enhanced through a generalized geodesic distance transform, and refined finally with a joint bilateral filter. We also propose to capture the rich feature context  around  each  pixel  by  using  an  adaptive  cross  region data  structure,  which  gives  a  higher  discriminative  power  than a  single  pixel-based  estimation.  The  high-level  object  cues  from the detector and the shape are then integrated with the low-level pixel cues and mid-level contour cues into a principled conditional random  field  (CRF)  framework,  which  can  be  efficiently  solved by  using  fast  graph  cut  algorithms.  We  evaluate  our  method over a newly created NTU-MHIC human dataset, which contains 351 images with manually annotated ground-truth segmentation.Both visual and quantitative results demonstrate that our method achieves state-of-the-art performance for the MHIC task\r\n\r\nWe introduce the first and the largest multiple human foreground cosegmentation and identification dataset – the NTU-MHIC dataset. In fact, till now there exists no benchmark dataset to evaluate a method’s performance for the MHIC task. The FlickrMFC dataset [a] contains some subsets with human classes, but some of them are not so challenging for the MHIC task. In addition, other object classes are also mixed with the human classes in this dataset. The CoDel dataset [b] is intended for a multiple foreground human detection task by sampling representative video frames in “Big Bang Theory”, but it only comes with bounding box labels. As one of our main contributions, we create a new dataset by collecting image subsets which match the MHIC scenario from both the FlickrMFC and CoDel datasets. We manually annotate the images with pixel wise class labels, which serve as the ground-truth to evaluate various MHIC algorithms. We also provide annotation tools to facilitate further research from Co-authors' website.\r\n\r\n###Citation\r\n\r\nPlease cite the following publication if you used or was inspired by our dataset/work:\r\n\r\n[1] Hongyuan Zhu, Jiangbo Lu, Jianfei Cai, Jianmin Zheng, Shijian Lu, Nadia Magnenat-Thalmann: Multiple Human Identification and Cosegmentation: A Human-Oriented CRF Approach with Poselets, IEEE Transaction on Multimedia, 2016\r\n\r\n[2] Hongyuan Zhu, Jiangbo Lu, Jianfei Cai, Jianmin Zheng, Nadia Magnenat-Thalmann: Poselet-based multiple human identification and cosegmentation. ICIP 2014\r\n\r\n[3] Hongyuan Zhu, Jiangbo Lu, Jianfei Cai, Jianmin Zheng, Nadia Magnenat-Thalmann: Multiple foreground recognition and cosegmentation: An object-oriented CRF model with robust higher-order potentials. WACV 2014\r\n\r\n[4] Hongyuan Zhu, Fanman Meng, Jianfei Cai, Shijian Lu: Beyond pixels: A comprehensive survey from bottom-up to semantic image segmentation and cosegmentation. J. Visual Communication and Image Representation 34: 12-27 (2016)\r\n\r\n###Related References:\r\n\r\n[a] Gunhee Kim, Eric P. Xing: On multiple foreground cosegmentation. CVPR 2012\r\n\r\n[b] Jianping Shi, Renjie Liao and Jiaya Jia CoDeL: An Human Co-detection and Labeling Framework, ICCV 2013\r\n\r\n###Contact:\r\n\r\nHongyuan Zhu (zhuh at i2r.a-star.edu.sg)\r\n\r\nJiangbo Lu  (Jiangbo.Lu at adsc.com.sg) https://sites.google.com/site/jiangbolu/\r\n\r\nJianfei Cai (ASJFCai at ntu.edu.sg) http://www.ntu.edu.sg/home/asjfcai/\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}